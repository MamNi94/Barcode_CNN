{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_frame_and_annotation(frame, bbox, image_filename):\n",
    "    image_dir = 'dataset/images/'\n",
    "    annotation_dir = 'dataset/annotations/'\n",
    "    # Save image\n",
    "    image_path = os.path.join(image_dir, image_filename)\n",
    "    print(image_path)\n",
    "   \n",
    "    cv2.imwrite(image_path, frame)\n",
    "\n",
    "    # Create XML annotation\n",
    "    annotation = ET.Element('annotation')\n",
    "    filename = ET.SubElement(annotation, 'filename')\n",
    "    filename.text = image_filename\n",
    "\n",
    "    size = ET.SubElement(annotation, 'size')\n",
    "    width_elem = ET.SubElement(size, 'width')\n",
    "    width_elem.text = str(frame.shape[1])  # Assuming frame is BGR format\n",
    "    height_elem = ET.SubElement(size, 'height')\n",
    "    height_elem.text = str(frame.shape[0])\n",
    "    depth_elem = ET.SubElement(size, 'depth')\n",
    "    depth_elem.text = str(frame.shape[2])\n",
    "\n",
    "    object_elem = ET.SubElement(annotation, 'object')\n",
    "    name = ET.SubElement(object_elem, 'name')\n",
    "    name.text = 'barcode'\n",
    "    bndbox = ET.SubElement(object_elem, 'bndbox')\n",
    "    xmin = ET.SubElement(bndbox, 'xmin')\n",
    "    xmin.text = str(bbox[0])\n",
    "    ymin = ET.SubElement(bndbox, 'ymin')\n",
    "    ymin.text = str(bbox[1])\n",
    "    xmax = ET.SubElement(bndbox, 'xmax')\n",
    "    xmax.text = str(bbox[2])\n",
    "    ymax = ET.SubElement(bndbox, 'ymax')\n",
    "    ymax.text = str(bbox[3])\n",
    "\n",
    "    # Save XML annotation file\n",
    "    annotation_file = os.path.join(annotation_dir, os.path.splitext(image_filename)[0] + '.xml')\n",
    "    tree = ET.ElementTree(annotation)\n",
    "    tree.write(annotation_file)\n",
    "\n",
    "    print(f\"Saved image: {image_path} and annotation: {annotation_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCaptureThread:\n",
    "    def __init__(self, src=0):\n",
    "        x_resolution = 2600\n",
    "        y_resolution = 2600\n",
    "        self.capture = cv2.VideoCapture(src)\n",
    "        self.capture .set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "    \n",
    "        self.capture.set(cv2.CAP_PROP_FPS, 30)\n",
    "        self.capture.set(cv2.CAP_PROP_FRAME_WIDTH, x_resolution)\n",
    "        self.capture.set(cv2.CAP_PROP_FRAME_HEIGHT, y_resolution)\n",
    "\n",
    "        #check actual Data\n",
    "        actual_width = self.capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        actual_height = self.capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "        actual_fps = self.capture.get(cv2.CAP_PROP_FPS)\n",
    "        print(f\"Resolution: {actual_width} x {actual_height}\")\n",
    "        print(f\"Frame Rate: {actual_fps}\")\n",
    "        self.ret, self.frame = self.capture.read()\n",
    "        self.running = True\n",
    "        self.thread = threading.Thread(target=self.update, args=())\n",
    "        self.thread.start()\n",
    "\n",
    "    def update(self):\n",
    "        while self.running:\n",
    "            self.ret, self.frame = self.capture.read()\n",
    "\n",
    "    def read(self):\n",
    "        return self.ret, self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        self.thread.join()\n",
    "        self.capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_boundingbox(frame, K_pre, K, K_post,threshold_value,K_morph):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blurred = cv2.GaussianBlur(gray, K_pre,0)\n",
    "        \n",
    "    # Compute the gradient in the x and y direction\n",
    "    gradX = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
    "    gradY = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=-1)\n",
    "\n",
    "    # Subtract the y-gradient from the x-gradient\n",
    "    gradient = cv2.subtract(gradX, gradY)\n",
    "    gradient = cv2.convertScaleAbs(gradient)\n",
    "    #v2.imshow('gradient', gradient)\n",
    "    # Blur the gradient image\n",
    "    blurred = cv2.GaussianBlur(gradient, K_post, 0)\n",
    "    #cv2.imshow('blurr', blurred)\n",
    "    # Apply a binary threshold to the blurred image\n",
    "    _,  thresh = cv2.threshold(blurred, threshold_value , 255, cv2.THRESH_BINARY)\n",
    "    #cv2.imshow('thresh', thresh)\n",
    "    # Construct a closing kernel and apply it to the thresholded image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, K_morph)\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    # Perform a series of erosions and dilations to remove small blobs\n",
    "    closed = cv2.erode(closed, None, iterations=10)\n",
    "    closed = cv2.dilate(closed, None, iterations=10)\n",
    "\n",
    "    #cv2.imshow('closed', closed)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(closed.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort the contours by area, keeping only the largest one\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    barcodeContour = None\n",
    "  \n",
    "    if contours:\n",
    "        # Assume the largest contour is the barcode\n",
    "        barcodeContour = contours[0]\n",
    "\n",
    "        # Compute the bounding box of the barcode region and draw it on the image\n",
    "        rect = cv2.minAreaRect(barcodeContour)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        \n",
    "        box = np.int32(box)\n",
    "    \n",
    "        #cut reigon\n",
    "        width = int(rect[1][0])\n",
    "        height = int(rect[1][1])\n",
    "\n",
    "        # Get the rotation matrix   \n",
    "        angle = rect[2]\n",
    "      \n",
    "        if width < height:\n",
    "            angle = angle + 90\n",
    "\n",
    "  \n",
    "        M = cv2.getRotationMatrix2D(rect[0], angle, 1.0)\n",
    "        # Rotate the entire image\n",
    "        rotated = cv2.warpAffine(gray, M, (gray.shape[1], gray.shape[0]))\n",
    "\n",
    "        ###Rotate Box#############\n",
    "        rotated_box = cv2.transform(np.array([box]), M)[0]\n",
    "\n",
    "        # Convert the rotated box points to integer coordinates\n",
    "        rotated_box = np.int32(rotated_box)\n",
    "        #print(rotated_box[0], rotated_box[1], rotated_box[2], rotated_box[3], )\n",
    "        #cv2.drawContours(rotated, [rotated_box], -1, (0, 255, 0), 2)\n",
    "         #########Test#############3\n",
    "        # Extract the rotated bounding box coordinates\n",
    "        x, y, w, h = cv2.boundingRect(rotated_box)\n",
    "        #dim= max(w,h) #+ 100\n",
    "        cropped = rotated[y:y+h, x:x+w]\n",
    "    \n",
    "        if cropped.size > 0:\n",
    "            cv2.imshow('Cropped Image', cropped)\n",
    "\n",
    "\n",
    "           \n",
    "       \n",
    "            \n",
    "     \n",
    "                    \n",
    "    return rotated_box,gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution: 2592.0 x 1944.0\n",
      "Frame Rate: 30.0\n",
      "dataset/images/image0.jpg\n",
      "Saved image: dataset/images/image0.jpg and annotation: dataset/annotations/image0.xml\n",
      "dataset/images/image1.jpg\n",
      "Saved image: dataset/images/image1.jpg and annotation: dataset/annotations/image1.xml\n",
      "dataset/images/image2.jpg\n",
      "Saved image: dataset/images/image2.jpg and annotation: dataset/annotations/image2.xml\n",
      "dataset/images/image3.jpg\n",
      "Saved image: dataset/images/image3.jpg and annotation: dataset/annotations/image3.xml\n",
      "dataset/images/image4.jpg\n",
      "Saved image: dataset/images/image4.jpg and annotation: dataset/annotations/image4.xml\n",
      "dataset/images/image5.jpg\n",
      "Saved image: dataset/images/image5.jpg and annotation: dataset/annotations/image5.xml\n",
      "dataset/images/image6.jpg\n",
      "Saved image: dataset/images/image6.jpg and annotation: dataset/annotations/image6.xml\n",
      "dataset/images/image7.jpg\n",
      "Saved image: dataset/images/image7.jpg and annotation: dataset/annotations/image7.xml\n",
      "dataset/images/image8.jpg\n",
      "Saved image: dataset/images/image8.jpg and annotation: dataset/annotations/image8.xml\n",
      "dataset/images/image9.jpg\n",
      "Saved image: dataset/images/image9.jpg and annotation: dataset/annotations/image9.xml\n",
      "dataset/images/image10.jpg\n",
      "Saved image: dataset/images/image10.jpg and annotation: dataset/annotations/image10.xml\n",
      "dataset/images/image11.jpg\n",
      "Saved image: dataset/images/image11.jpg and annotation: dataset/annotations/image11.xml\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'rotated_box' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Failed to capture frame.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m box,gray  \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_boundingbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_morph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     22\u001b[0m     capture_frame_and_annotation(frame,box,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 83\u001b[0m, in \u001b[0;36mdetect_boundingbox\u001b[0;34m(frame, K_pre, K, K_post, threshold_value, K_morph)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cropped\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCropped Image\u001b[39m\u001b[38;5;124m'\u001b[39m, cropped)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrotated_box\u001b[49m,gray\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'rotated_box' where it is not associated with a value"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "K= 7\n",
    "K_pre = (3,3)\n",
    "K_post = (K,K)\n",
    "threshold_value = 255/2\n",
    "K_morph = (21,21)\n",
    "\n",
    "\n",
    "def main():\n",
    "    cap_thread = VideoCaptureThread()\n",
    "    i = 0\n",
    "    while True:\n",
    " \n",
    "        ret, frame = cap_thread.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "        \n",
    "        box,gray  = detect_boundingbox(frame, K_pre, K, K_post, threshold_value, K_morph)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            capture_frame_and_annotation(frame,box,f'image{i}.jpg')\n",
    "            i +=1\n",
    "        scale_factor = 0.3 # This will scale the image to half its original size\n",
    "\n",
    "        # Calculate the new dimensions of the image\n",
    "        new_width = int(frame.shape[1] * scale_factor)\n",
    "        new_height = int(frame.shape[0] * scale_factor)\n",
    "        resized_image = cv2.resize(frame, (new_width, new_height))\n",
    "        cv2.imshow('Frame', resized_image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap_thread.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scanning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
